---
title: "MODELOS LINEARES GENERALIZADOS (EST082)"
subtitle: "RESOLUÇÃO - LISTA 1"
lang: pt
author: "Jaqueline Lamas da Silva"
knitr:
    opts_chunk: 
      fig.align: 'center'
format: 
  html:
    self-contained-math: true
    embed-resources: true
    code-fold: true
toc: true
editor: source
---


```{r, echo=FALSE, warning=FALSE}
suppressMessages(library("dplyr"))
suppressMessages(library("MASS"))
source("envel_norm.r")

```

# Parte A: **Paula (2013), Cap. 1**

**Análise de resíduo, validação do modelo e análise de diagnóstico.**


## 19

**Variáveis:**

* (i) estado (nome do estado);
* (ii) pop(população estimada em julho de 1975); 
* (iii) percap (renda percapita em 1974 em USD);
* (iv) analf (proporção de analfabetos em 1970), 
* (v) expvida (expectativa de vida em anos 1969-70);
* (vi) crime (taxa de criminalidade por 100000 habitantes 1976);
* (vii) estud (porcentagem de estudantes que concluem o segundo grau 1970);
* (viii) ndias (número de dias do ano com temperatura abaixo de zero grau Celsus na cidade mais importante do estado);
* (ix) area (área do estado em milhas quadradas).



```{r}
reg3 <-read.table("./dados/lista1/reg3.txt", quote="\"")
# Nomear as colunas do data frame
colnames(reg3) <- c("estado",    # (i) Nome do estado
                    "pop",       # (ii) População estimada em julho de 1975
                    "percap",    # (iii) Renda per capita em 1974 em USD
                    "analf",     # (iv) Proporção de analfabetos em 1970
                    "expvida",   # (v) Expectativa de vida em anos 1969-70
                    "crime",     # (vi) Taxa de criminalidade por 100000 habitantes em 1976
                    "estud",     # (vii) Porcentagem de estudantes que concluem o segundo grau em 1970
                    "ndias",     # (viii) Número de dias do ano com temperatura abaixo de zero grau Celsius
                    "area")      # (ix) Área do estado em milhas quadradas
```
Queremos explicar e variável **expvida** usando um modelo de regressão normal linear dadas as variáveis explicativas percap, analf, crime, estud, ndias e dens, em que dens=pop/area.

### Análise exploratória

```{r, warning=FALSE}
reg3<- reg3 |>
  mutate(dens=pop/area)
attach(reg3)
painel.pearson <- function(x, y, ...) {
    horizontal <- (par("usr")[1] + par("usr")[2]) / 2;
    vertical <- (par("usr")[3] + par("usr")[4]) / 2;
    text(horizontal, vertical, format(abs(cor(x,y)), digits=2))
}

painel.prop <- function(x, y, ...){
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- round(cor(x, y), digits = 2)
  txt <- paste0("R = ", r)
  cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex = cex.cor * r)
}

pairs(reg3[,c(5,3,4,6,7,8,10)], main = "Expectativa de vida - Correlograma", pch = 20, col="aquamarine3", 
    lower.panel = painel.prop)

```
No gráfico acima temos o diagrama de dispersão de todas as possíveis variáveis explicativas com a resposta. Pelo gráfico de dispersão, as variáveis parecem estar relacionadas de forma linear com a expectativa de vida, isso pode ser verificado também pela correlação entre elas. Além disso, temos que algumas variáveis explicativas possuem relacionamento entre si, isso pode gerar problemas de multicolinearidade.

```{r}
ajuste0<-lm(expvida~percap+analf+crime+estud+ndias+dens, data = reg3)
```

### Seleção de variáveis

Vamos utilizar o critério AIC para selecionar as variáveis.
```{r}
ajuste<-stepAIC(ajuste0,direction="backward")
```
As variáveis selecionadas são: crime, estud, ndias, dens.

```{r}
modelo<-lm(expvida ~ crime + estud + ndias + dens, data=reg3)
summary(modelo)
```



### Análise de resíduos

*MODELO:* expvida ~ crime + estud + ndias + dens

```{r}
suppressMessages(attach(reg3))
y.hat<-modelo$fitted.values
res_stud<-rstudent(modelo)
res_pad<-rstandard(modelo)
plot(res_stud)
```

#### Normalidade

```{r}
envel_norm(modelo)
```

Os resíduos podem ser considerados normalmente distribuídos.

#### Homodedasticidade
```{r}
plot(y.hat,res_pad,xlab="Valores Ajustados", ylab="Resíduos Padronizados",pch=19)
```
Não foi identificado padrões que indiquem que os erros são heterocedásticos.

#### Resíduo x variável explicativa
```{r}
plot(crime, res_pad, pch=19)
plot(estud, res_pad, pch=19)
plot(ndias, res_pad, pch=19)
plot(dens, res_pad, pch=19)
```
Não parece haver mais nenhuma contribuição das variáveis explicativas crime, estud, ndias e dens.

**Modelo validado!**

### Análise de diagnóstico

```{r}
# X<-matrix(c(rep(1,50), crime, estud, ndias, dens), ncol=5, nrow=50, byrow = F)
# H<-X%*%solve(t(X)%*%X)%*%t(X)
# QMRes <- sum(modelo$residuals^2)/45  # quadrado medio dos residuos
# sigma2 <- ((n-p)/n)*QMRes

influ<-influence.measures(modelo)
deffits=influ$infmat[,6] # conferir coluna
cook=influ$infmat[,8] # conferir coluna
Hii=influ$infmat[,9] # conferir coluna

n<-nrow(reg3)
p<-5


corte=2*p/n
plot(Hii, pch=1, main='Pontos de alavanca', cex=0.5)
lines(1:n,corte*rep(1,n))
#identify(Hii, n=2, tolerance = 2)
```
Temos que duas observações que são pontos de alavanca: 28 e 40.


```{r}
corte=pf(0.5,p,n-p)
plot(cook)
lines(1:n,corte*rep(1,n), lty=2, col='maroon')
```

```{r}
summary(influ)
```
A observação 40 referente ao estado South-Carolina é apontada como influente, ela parece impactar na matriz de covariâncias e foi apontada como alavanca.

### Interpretação
```{r}
modelo
```
Temos que em um estado com uma taxa de criminalidade 0, com uma porcentagem de estudantes que concluíram o segundo grau de 0% e uma densidade populacional 2.684461 (máxima densidade do conjunto de dados) a expectativa de vida é aproximadamente 70 anos. 

* Com o aumento de uma unidade na taxa de criminalidade a expectativa de vida diminui em média 0.29 anos.

*  Com o aumento a porcentagem de estududantes a expectativa de vida aumenta em média 0.04 anos.

* Com o aumento de um unidade no número de dias com temperaturas abaixo de zero a expectativa de vida diminui em média 0.007 anos.

* Com o aumento de uma unidade na densidade populacional a expectativa de vida diminui em 0.45 anos.


## 20

* (i) telhados, total de telhados vendidos (em mil metros quadrados);
* (ii) gastos, gastos pela loja com promoções do produto (em mil USD);
* (iii) clientes, número de clientes cadastrados na loja (em milhares);
* (iv) marcas, número de marcas concorrentes do produto;
* (v) potencial, potencial da loja (quanto maior o valor maior o potencial). Um dos objetivos do estudo com esse conjunto de dados é tentar prever o número esperado de telhados vendidos dadas as variáveis explicativas.

```{r}
vendas<-read.table("./dados/lista1/vendas.txt", quote="\"")
colnames(vendas) <- c("telhados",   
                    "gastos",
                    "clientes",
                    "marcas",  
                    "potencial")     

```


### Análise exploratória

```{r, warning=FALSE}
attach(vendas)
pairs(vendas[,c(1:5)], main = "Telhados - Correlograma", pch = 20, col="aquamarine3", 
    lower.panel = painel.prop)

```
No gráfico acima temos o diagrama de dispersão de todas as possíveis variáveis explicativas com a resposta. A que não parece ter um relacionamento linear forte com a venda de telhados é o gasto com promoções do produto.

```{r}
ajuste0<-lm(telhados~gastos+marcas+potencial+clientes, data = vendas)
```
### Seleção de variáveis

Vamos utilizar o critério AIC para selecionar as variáveis.
```{r}
ajuste<-stepAIC(ajuste0,direction="backward")
```
As variáveis selecionadas são: gastos, marcas e clientes

```{r}
modelo<-lm(telhados ~ gastos + marcas + clientes)
summary(modelo)
```
Mesmo gastos não sendo significativa ela deve estar no modelo, esse modelo foi o selecionado pelo critério AIC.





### Análise de resíduos

*MODELO:* telhados ~ gastos + marcas + clientes

```{r}
suppressMessages(attach(vendas))
y.hat<-modelo$fitted.values
res_stud<-rstudent(modelo)
res_pad<-rstandard(modelo)
plot(res_stud)
```

#### Normalidade

```{r}
envel_norm(modelo)
```

Os resíduos podem ser considerados normalmente distribuídos.

#### Homodedasticidade
```{r}
plot(y.hat,res_pad,xlab="Valores Ajustados", ylab="Resíduos Padronizados",pch=19)
```
Não foi identificado padrões que indiquem que os erros são heterocedásticos.

#### Resíduo x variável explicativa
```{r}
plot(gastos, res_pad, pch=19)
plot(clientes, res_pad, pch=19)
plot(marcas, res_pad, pch=19)
```
Não parece haver mais nenhuma contribuição das variáveis explicativas gastos, clientes e marcas.

**Modelo validado!**

### Análise de diagnóstico

```{r}
influ<-influence.measures(modelo)
deffits=influ$infmat[,5] # conferir coluna
cook=influ$infmat[,7] # conferir coluna
Hii=influ$infmat[,8] # conferir coluna

n<-nrow(vendas)
p<-4


corte=2*p/n
plot(Hii, pch=1, main='Pontos de alavanca', cex=0.5)
lines(1:n,corte*rep(1,n),lty=2, col='maroon')
#identify(Hii, n=2, tolerance = 2)
```
A observação 6 parece ser ponto de alavanca.

```{r}
corte=pf(0.5,p,n-p)
plot(cook, ylim = c(0,corte+0.2))
lines(1:n,corte*rep(1,n), lty=2, col='maroon')
# identify(cook, n=2, tolerance = 1.5)
```
As observações 8 e 21 parecem ser influentes.

```{r}
summary(influ)
```
As observações 3 e 21 foram apontadas como influentes, elas parecem impactar na matriz de covariâncias.

### Interpretação
```{r}
modelo
```
* Com o aumento de uma unidade nos gastos com promoções do produto espera-se que as vendas aumentem em média 2 unidades aproximadamente.

*  Com o aumento de uma unidade no número de marcas concorrentes do produto espera-se que em média as vendas caiam em aproximadamente 21 unidades.

* Com o aumento de um unidade no número de clientes cadastrados na loja espera-se que em média o número de vendas aumente em aproximadamente 3 unidades.


## 22

(i) imposto do imóvel (em 100 USD);
(ii) área do terreno (em 1000 pés quadrados);
(iii) área construída (em 1000 pés quadrados);
(iv) idade da residência (em anos);
(v) preço de venda do imóvel (em 1000 USD). Ajuste um
modelo normal linear do preço de venda contra as demais variáveis.


```{r}
imoveis<-read.table("./dados/lista1/imoveis.txt", quote="\"")
colnames(imoveis) <- c("imposto",   
                    "area_terreno",
                    "area_const",
                    "idade",  
                    "preco")     

```


### Análise exploratória

```{r, warning=FALSE}
attach(imoveis)
pairs(imoveis[,c(1:5)], main = "Imoveis - Correlograma", pch = 20, col="aquamarine3", 
    lower.panel = painel.prop)

```
No gráfico acima temos o diagrama de dispersão de todas as possíveis variáveis explicativas com a resposta. As variáveis imposto, área do terreno e área construída possuem uma correlação bem alta com o preço de venda do imóvel. A idade do imóvel está correlacionada com o preço do imóvel de forma negativa.

```{r}
ajuste0<-lm(preco~imposto+area_const+area_terreno+idade, data = imoveis)
```
### Seleção de variáveis

Vamos utilizar o critério AIC para selecionar as variáveis.
```{r}
ajuste<-stepAIC(ajuste0,direction="backward")
```
As variáveis selecionadas são: imposto e área construída.

```{r}
modelo<-lm(preco ~ imposto + area_const )
summary(modelo)
```

### Análise de resíduos

*MODELO:* preco ~ imposto + area_const 

```{r}
suppressMessages(attach(imoveis))
y.hat<-modelo$fitted.values
res_stud<-rstudent(modelo)
res_pad<-rstandard(modelo)
plot(res_stud)
```
#### Normalidade

```{r}
envel_norm(modelo)
```

Os resíduos podem ser considerados normalmente distribuídos.

#### Homodedasticidade
```{r}
plot(y.hat,res_pad,xlab="Valores Ajustados", ylab="Resíduos Padronizados",pch=19)
```
Não foi identificado padrões que indiquem que os erros são heterocedásticos.

#### Resíduo x variável explicativa
```{r}
plot(imposto, res_pad, pch=19)
plot(area_const, res_pad, pch=19)
```
Não parece haver mais nenhuma contribuição das variáveis explicativas.

**Modelo validado!**

### Análise de diagnóstico

```{r}
influ<-influence.measures(modelo)
deffits=influ$infmat[,4] # conferir coluna
cook=influ$infmat[,6] # conferir coluna
Hii=influ$infmat[,7] # conferir coluna

n<-nrow(imoveis)
p<-3

corte=2*p/n
plot(Hii, pch=1, main='Pontos de alavanca', cex=0.5, ylim=c(0,0.4))
lines(1:n,corte*rep(1,n),lty=2, col='maroon')
#identify(Hii, n=2, tolerance = 2)
```
A observação 10 parece ser ponto de alavanca.

```{r}
corte=pf(0.5,p,n-p)
plot(cook)
lines(1:n,corte*rep(1,n), lty=2, col='maroon')
# identify(cook, n=2, tolerance = 1.5)
```
As observações 10 e 27 parecem ser influentes.

```{r}
summary(influ)
```
As observações 9, 10 e 27 foram apontadas como influentes. A 27 é ponto de alavanca e influencia na matriz de covariâncias e na estimação dos betas. 

### Interpretação
```{r}
modelo
```
* Com o aumento de uma unidade no valor do imposto espera-se que o preco de venda aumente em média 2 (1000 USD) aproximadamente.

* Com o aumento de uma unidade na área construída espera-se que em média o preco do imovel aumente em aproximadamente 14 mil dólares americanos.




## 23

No arquivo trees.dat é apresentado um conjunto de dados que tem sido analisado sob diversos pontos de vista por vários pesquisadores (ver, por exemplo, Jørgensen, 1989). As variáveis observadas são o diâmetro (d), a altura (h) e o volume (v) de uma amostra de 31 cerejeiras numa floresta do estado da Pensilvânia, EUA. 

```{r}
trees<-read.table("./dados/lista1/trees.txt", quote="\"")
colnames(trees) <- c("d",   
                    "h",
                    "v")  
```
```{r}
trees<-trees |>
  mutate(ld=log(d),lh=log(h),lv=log(v))
```

```{r}
suppressMessages(attach(trees))
modelo<-lm(lv~ld+lh)
summary(modelo)
```
### Análise de resíduos

*MODELO:* log(v) ~ a + blog(d)+clog(h) 

```{r}
y.hat<-modelo$fitted.values
res_stud<-rstudent(modelo)
res_pad<-rstandard(modelo)
plot(res_stud)
```
#### Normalidade

```{r}
envel_norm(modelo)
```

Os resíduos podem ser considerados normalmente distribuídos.

#### Homodedasticidade
```{r}
plot(y.hat,res_pad,xlab="Valores Ajustados", ylab="Resíduos Padronizados",pch=19)
```
Não foi identificado padrões que indiquem que os erros são heterocedásticos.

#### Resíduo x variável explicativa
```{r}
plot(ld, res_pad, pch=19)
plot(lh, res_pad, pch=19)
```
Não parece que o modelo possa ser melhorado ao incluir mais termos das variáveis explicativas.

**Modelo validado!**

### Análise de diagnóstico

```{r}
influ<-influence.measures(modelo)
deffits=influ$infmat[,4] # conferir coluna
cook=influ$infmat[,6] # conferir coluna
Hii=influ$infmat[,7] # conferir coluna

n<-nrow(trees)
p<-3

corte=2*p/n
plot(Hii, pch=1, main='Pontos de alavanca', cex=0.5, ylim=c(0,0.4))
lines(1:n,corte*rep(1,n),lty=2, col='maroon')
#identify(Hii, n=2, tolerance = 2)
```
A observação 20 parece ser ponto de alavanca.

```{r}
corte=pf(0.5,p,n-p)
plot(cook)
lines(1:n,corte*rep(1,n), lty=2, col='maroon')
# identify(cook, n=2, tolerance = 1.5)
```
Nenhuma observação parece influente em termos da distância de cook.

```{r}
summary(influ)
```
As observações 3, 20 e 31 foram apontadas como influentes, elas parecem impactar na matriz de covariâncias. 


### Interpretação
```{r}
modelo
```
* Com o aumento de uma unidade no diâmetro espera-se que em média o volume aumento de 1.983 no volume.

* Com o aumento de uma unidade altura espera-se um aumento de 1.117.

## 24

Tbill (taxa de retorno livre de risco), retorno Microsoft, SP500 (retorno do mercado), retorno GE e retorno FORD de janeiro de 2002 a abril de
2003.

```{r}
capm<-read.table("./dados/lista1/capm.txt", quote="\"")
colnames(capm) <- c("Tibill",
                    "Micros",   
                    "SP500",
                    "GE",
                    "Ford")  

capm<-capm |>
  mutate(exc.M=Micros-SP500,exc.GE=GE-SP500,exc.F=Ford-SP500, exc.mercado=SP500-Tibill)
```

##### Microsoft

```{r}
attach(capm)
plot(exc.M~exc.mercado, main="Microsoft")
n<-nrow(capm)
p<-2
ml1<-lm(exc.M~exc.mercado)
summary(ml1)

t.quantil<-qt(0.025,df=n-p, lower.tail = F)
LI<-(-0.02558) - 0.07406*sqrt(t.quantil)
LS<-(-0.02558) + 0.07406*sqrt(t.quantil)
```

* O parâmetro $\alpha$ não é significativo para o modelo.

* IC($\beta_1$,95%) = [`r LI`; `r LS`], o intervalo para beta inclui o valor zero. Dessa forma, não podemos dizer que ele é diferente de 0.
O parâmetro beta também não é significativo.


**Análise dos resíduos**

```{r}
y.hat<-ml1$fitted.values
res_stud<-rstudent(ml1)
plot(y.hat,res_stud)
```
```{r}
envel_norm(ml1)
```
Os resíduos parecem bem comportados. Mas o modelo não foi validado, os parâmetros não são significativos.

**Diagnóstico**

Em termos práticos, o modelo não foi validado e não teríamos chegado nessa etapa.

```{r}
influ<-influence.measures(ml1)
deffits=influ$infmat[,3] # conferir coluna
cook=influ$infmat[,5] # conferir coluna
Hii=influ$infmat[,6] # conferir coluna

n<-nrow(capm)
p<-2

corte=2*p/n
plot(Hii, pch=1, main='Pontos de alavanca', cex=0.5)
lines(1:n,corte*rep(1,n),lty=2, col='maroon')
#identify(Hii, n=2, tolerance = 2)
```
Temos algumas observações como ponto de alavanca.

```{r}
corte=pf(0.5,p,n-p)
plot(cook)
lines(1:n,corte*rep(1,n), lty=2, col='maroon')
# identify(cook, n=2, tolerance = 1.5)
```
Nenhuma observação parece influente em termos da distância de cook.
```{r}
dffit=influ$infmat[,3]
corte=2*sqrt(p/(n-p))
plot(dffit)
lines(1:n,corte*rep(1,n), col="maroon")

```
```{r}
summary(influ)
```
Algumas observações são apontadas como influentes em termos da medida Dffit.

##### Ford


```{r}
plot(exc.F~exc.mercado, main="Ford")
ml2<-lm(exc.F~exc.mercado)
summary(ml2)

t.quantil<-qt(0.025,df=n-p, lower.tail = F)
LI<-(0.18828) -  0.09258*sqrt(t.quantil)
LS<-(0.18828) +  0.09258*sqrt(t.quantil)
```
* O parâmetro $\alpha$ não é significativo para o modelo.

* IC($\beta_1$,95%) = [`r LI`; `r LS`], temos 95% de confiabilidade de que o intervalo inclui o verdadeiro valor do parâmetro.




**Análise dos resíduos**

```{r}
y.hat<-ml2$fitted.values
res_stud<-rstudent(ml2)
plot(res_stud)
```
Temos 4 observações atípicas 190,199,222 e 229.
```{r}
envel_norm(ml2)
```
Os resíduos parecem bem comportados.

**Diagnóstico**
```{r}
influ<-influence.measures(ml2)
deffits=influ$infmat[,3] # conferir coluna
cook=influ$infmat[,5] # conferir coluna
Hii=influ$infmat[,6] # conferir coluna

n<-nrow(capm)
p<-2

corte=2*p/n
plot(Hii, pch=1, main='Pontos de alavanca', cex=0.5)
lines(1:n,corte*rep(1,n),lty=2, col='maroon')
#identify(Hii, n=2, tolerance = 2)
```
Temos algumas observações que são alavanca.

```{r}
corte=pf(0.5,p,n-p)
plot(cook)
lines(1:n,corte*rep(1,n), lty=2, col='maroon')
# identify(cook, n=2, tolerance = 1.5)
```

Nenhuma observação parece influente em termos da distância de cook.
```{r}
dffit=influ$infmat[,3]
corte=2*sqrt(p/(n-p))
plot(dffit)
lines(1:n,corte*rep(1,n), col="maroon")
```

```{r}
summary(influ)
```
Algumas observações são apontadas como influentes em termos da medida Dffit também, inclusive as que foram apontadas como atípicas.

###### GE
```{r}
plot(exc.GE~exc.mercado, main="GE")
ml3<-lm(exc.GE~exc.mercado)
summary(ml3)


t.quantil<-qt(0.025,df=n-p, lower.tail = F)
LI<-(0.31153) -  0.05168*sqrt(t.quantil)
LS<-(0.31153) +  0.05168*sqrt(t.quantil)
```
* O parâmetro $\alpha$ não é significativo para o modelo.

* IC($\beta_1$,95%) = [`r LI`; `r LS`], o intervalo contém o verdadeiro valor do parâmetro com 95% de confiabilidade.

**Análise dos resíduos**

```{r}
y.hat<-ml3$fitted.values
res_stud<-rstudent(ml3)
plot(res_stud)
```
Temos algumas observações discrepantes: 68, 131, 175 e 222.

```{r}
envel_norm(ml3)
```
Os resíduos parecem bem comportados, apesar das observações atípicas.

**Diagnóstico**

```{r}
influ<-influence.measures(ml3)
deffits=influ$infmat[,3] # conferir coluna
cook=influ$infmat[,5] # conferir coluna
Hii=influ$infmat[,6] # conferir coluna

n<-nrow(capm)
p<-2

corte=2*p/n
plot(Hii, pch=1, main='Pontos de alavanca', cex=0.5)
lines(1:n,corte*rep(1,n),lty=2, col='maroon')
#identify(Hii, n=2, tolerance = 2)
```
Temos algumas observações como ponto de alavanca.

```{r}
corte=pf(0.5,p,n-p)
plot(cook)
lines(1:n,corte*rep(1,n), lty=2, col='maroon')
# identify(cook, n=2, tolerance = 1.5)
```
Nenhuma observação parece influente em termos da distância de cook.
```{r}
dffit=influ$infmat[,3]
corte=2*sqrt(p/(n-p))
plot(dffit)
lines(1:n,corte*rep(1,n), col="maroon")

```

```{r}
summary(influ)
```
Algumas observações são apontadas como influentes em termos da medida Dffif, essa lista inclui as observações com resíduo alto.

## 25

* (i) o preço de venda de um imóvel (em mil
USD);
* (ii) a área total (em pés quadrados).

```{r}
area <- c(800, 950, 910, 950, 1200, 1000, 1180, 1000,
            1380, 1250, 1500, 1200, 1600, 1650, 1600, 1680,
            1500, 1780, 1790, 1900, 1760, 1850, 1800, 1700,
            1370, 2000, 2000, 2100, 2050, 1990, 2150, 2050,
            2200, 2200, 2180, 2250, 2400, 2350, 2500, 2500,
            2500, 2500, 2680, 2210, 2750, 2500, 2400, 3100,
            2100, 4000)
preco<- c(30.6, 31.5, 33.3, 45.9, 47.4, 48.9, 51.6, 53.1,
             54.0, 54.3, 55.2, 55.2, 56.7, 57.9, 58.5, 59.7,
             60.9, 60.9, 62.4, 63.0, 64.5, 66.0, 66.3, 67.5,
             68.4, 68.4, 68.7, 69.6, 70.5, 74.7, 75.0, 75.3,
             79.8, 80.7, 80.7, 83.4, 84.0, 86.1, 87.0, 90.3,
             96.0, 101.4, 105.9, 111.3, 112.5, 114.0, 115.2, 117.0,
             129.0, 165.0)
venda <- data.frame(area,preco)
colnames(venda) <- c("area","preco")
suppressMessages(attach(venda))
```


### Análise exploratória

```{r, warning=FALSE}
pairs(venda[,c(1:2)], main = "Venda Imóveis - Correlograma", pch = 20, col="aquamarine3", 
    lower.panel = painel.prop)

```
No gráfico acima temos o diagrama de dispersão do preço e da área, possuem uma correlação bem alta.

```{r}
modelo<-lm(preco~area, data = venda)
```

```{r}
summary(modelo)
```

### Análise de resíduos

*MODELO:* preco ~ area 

```{r}
y.hat<-modelo$fitted.values
res_stud<-rstudent(modelo)
res_pad<-rstandard(modelo)
plot(res_stud)
```
Observação 49 é atípica.
#### Normalidade

```{r}
envel_norm(modelo)
```

Os resíduos não podem ser considerados normalmente distribuídos.

#### Homodedasticidade
```{r}
plot(y.hat,res_pad,xlab="Valores Ajustados", ylab="Resíduos Padronizados",pch=19)
```
Não foi identificado padrões que indiquem que os erros são heterocedásticos.

#### Resíduo x variável explicativa
```{r}
plot(area, res_pad, pch=19)
```
Não parece haver mais nenhuma contribuição da variável explicativa.

**Modelo não validado!!!**

##### Tranformação log(preco)

Vamos tentar a transfromação log para tentar normalizar os resíduos.
```{r}
modelo<-lm(log(preco)~area)
summary(modelo)
```
```{r}
y.hat<-modelo$fitted.values
res_stud<-rstudent(modelo)
res_pad<-rstandard(modelo)
plot(res_stud)
```
Observação 49 é atípica.

#### Normalidade

```{r}
envel_norm(modelo)
```

Agora parece razoável dizer que os resíduos são normalmente distribuídos.

#### Homodedasticidade
```{r}
plot(y.hat,res_pad,xlab="Valores Ajustados", ylab="Resíduos Padronizados",pch=19)
```
Não foi identificado padrões que indiquem que os erros são heterocedásticos.

#### Resíduo x variável explicativa
```{r}
plot(area, res_pad, pch=19)
```
Nenhum padrão.

**Modelo validado após a transformação: log(preco) ~ area**


### Análise de diagnóstico

```{r}
influ<-influence.measures(modelo)
deffits=influ$infmat[,3] # conferir coluna
cook=influ$infmat[,5] # conferir coluna
Hii=influ$infmat[,6] # conferir coluna

n<-nrow(venda)
p<-3

corte=2*p/n
plot(Hii, pch=1, main='Pontos de alavanca', cex=0.5, ylim=c(0,0.4))
lines(1:n,corte*rep(1,n),lty=2, col='maroon')
#identify(Hii, n=2, tolerance = 2)
```
A observação 50, além de ser atípica é ponto de alavanca.
```{r}
corte=pf(0.5,p,n-p)
plot(cook)
lines(1:n,corte*rep(1,n), lty=2, col='maroon')
# identify(cook, n=2, tolerance = 1.5)
```
A observação 50 também parece ser influente.

```{r}
summary(influ)
```
A observação 50 é preocupante.


# Parte B 

Ajustar modelos de regressão aos dados (y_ex1.txt,X_ex1.txt), (y_ex2.txt,X_ex2.txt) e (y_ex3.txt,X_ex3.txt). Verificar pressupostos e
fazer eventuais correções.

## Exemplo 1
```{r}
suppressMessages(y_ex1 <- read.table("C:/ufjf/2024.3/ModelosLinearesGeneralizados/dados/lista1/y_ex1.txt", quote="\"", comment.char=""))

library(readr)
X_ex1 <- read_table("dados/lista1/X_ex1.txt")
d1<-cbind(y_ex1,X_ex1)
suppressMessages(colnames(d1)<-c("y","x1","x2","x3"))
```

### Análise exploratória

```{r, warning=FALSE}
pairs(d1[,c(1,3,4)], main = "Correlograma", pch = 20, col="aquamarine3", 
    lower.panel = painel.prop)

```
No gráfico acima temos o diagrama de dispersão das explicativas com a resposta.
```{r}
suppressMessages(attach(d1))
modelo<-lm(y~1+x2+x3, data = d1)
summary(modelo)
```


### Análise de resíduos

```{r}
y.hat<-modelo$fitted.values
res_stud<-rstudent(modelo)
res_pad<-rstandard(modelo)
plot(res_stud)
```
#### Normalidade

```{r}
envel_norm(modelo)
```

Os resíduos estão bem comportados e podemos assumir normalidade.

#### Homodedasticidade
```{r}
plot(y.hat,res_stud,xlab="Valores Ajustados", ylab="Resíduos Padronizados",pch=19)
```
Não foi identificado padrões que indiquem que os erros são heterocedásticos.

#### Resíduo x variável explicativa
```{r}
attach(d1)
plot(x2, res_pad, pch=19)
plot(x3, res_pad, pch=19)

```
Não parece haver mais nenhuma contribuição das variáveis explicativas.

**Modelo  y ~ 1+ x2 + x3 validado, os presuposto foram atendidos!!!**


## Exemplo 2
```{r}
suppressMessages(y_ex2 <- read.table("C:/ufjf/2024.3/ModelosLinearesGeneralizados/dados/lista1/y_ex2.txt", quote="\"", comment.char=""))

library(readr)
X_ex2 <- read_table("dados/lista1/X_ex2.txt", 
    col_names = FALSE)
d2<-cbind(y_ex2,X_ex2)
suppressMessages(colnames(d2)<-c("y","x1","x2","x3"))
```

### Análise exploratória

```{r, warning=FALSE}
pairs(d2[,c(1,3,4)], main = "Correlograma", pch = 20, col="aquamarine3", 
    lower.panel = painel.prop)

```
No gráfico acima temos o diagrama de dispersão das explicativas com a resposta.
```{r}
suppressMessages(attach(d2))
modelo<-lm(y~1+x2+x3, data = d1)
summary(modelo)
```

### Análise de resíduos

```{r}
y.hat<-modelo$fitted.values
res_stud<-rstudent(modelo)
res_pad<-rstandard(modelo)
plot(res_stud)
```
#### Normalidade

```{r}
envel_norm(modelo)
```

Os resíduos estão bem comportados e podemos assumir normalidade.

#### Homodedasticidade
```{r}
plot(y.hat,res_pad,xlab="Valores Ajustados", ylab="Resíduos Padronizados",pch=19)
```
Não foi identificado padrões que indiquem que os erros são heterocedásticos.

#### Resíduo x variável explicativa
```{r}
suppressMessages(attach(d2))
plot(x2, res_pad, pch=19)
plot(x3, res_pad, pch=19)

```
Não parece haver mais nenhuma contribuição das variáveis explicativas.

**Modelo  y ~ 1+ x2 + x3 validado, os presuposto foram atendidos!!!**



## Exemplo 3

```{r}
suppressMessages(y_ex3 <- read.table("C:/ufjf/2024.3/ModelosLinearesGeneralizados/dados/lista1/y_ex3.txt", quote="\"", comment.char=""))

library(readr)
X_ex3 <- read_table("dados/lista1/X_ex3.txt", 
    col_names = FALSE)
d3<-cbind(y_ex3,X_ex3)
suppressMessages(colnames(d3)<-c("y","x1","x2","x3"))
```

### Análise exploratória

```{r, warning=FALSE}
pairs(d3[,c(1,3,4)], main = "Correlograma", pch = 20, col="aquamarine3",
      lower.panel = painel.prop)

```
No gráfico acima temos o diagrama de dispersão das explicativas com a resposta. A variável possui um relacionamento não linear com a resposta.
```{r}
suppressMessages(attach(d3))
modelo<-lm(y~1+x2+x3, data = d3)
summary(modelo)
```
### Seleção de variáveis
```{r}
stepAIC(modelo, direction = "backward")
```
O intercepto e x3 não são significativas, porém o modelo com ela é o que possui menor AIC.

**MODELO:** y ~ 1 + x2 + x3

### Análise de resíduos

```{r}
y.hat<-modelo$fitted.values
res_stud<-rstudent(modelo)
res_pad<-rstandard(modelo)
plot(res_stud)
```
#### Normalidade

```{r}
envel_norm(modelo)
```

Os resíduos não podem ser considerados normais.

#### Homodedasticidade
```{r}
plot(y.hat,res_stud,xlab="Valores Ajustados", ylab="Resíduos Padronizados",pch=19)
```
O padrão nos resíduos é igual ao do gráfico de dispersão da variável x2 com a resposta.

#### Resíduo x variável explicativa
```{r}

plot(x2, res_stud, pch=19)
plot(x3, res_stud, pch=19)

```
Vamos incluir a variável $x_2^2$.

**Modelo  y ~ 1+ x2 + x3 não está validado validado, os presuposto não foram atendidos!!!**

**MODELO:** y ~ 1 + x2 + x3 + x2^2

```{r}
modelo<-lm(y~1+x2+x3+I(x2^2))
summary(modelo)
```

### Análise de resíduos

```{r}
y.hat<-modelo$fitted.values
res_stud<-rstudent(modelo)
res_pad<-rstandard(modelo)
plot(res_stud)
```
#### Normalidade

```{r}
envel_norm(modelo)
```

Os resíduos ainda não podem ser considerados normais.

#### Homodedasticidade
```{r}
plot(y.hat,res_stud,xlab="Valores Ajustados", ylab="Resíduos estudentizados",pch=19)
```
Os resíduos não parecem ter variância constante.

#### Resíduo x variável explicativa
```{r}
plot(x2, res_stud, pch=19)
plot(x3, res_stud, pch=19)
```
Vamos incluir a variável $x_3^2$.

**Modelo  y ~ 1+ x2 + x2^2 + x3 não está validado validado, os presuposto não foram atendidos!!!**

### Mudanças

```{r}
modelo<-lm(y~1+x2+x3+I(x2^2)+I(x3^2))
summary(modelo)
```

### Análise de resíduos

```{r}
y.hat<-modelo$fitted.values
res_stud<-rstudent(modelo)
res_pad<-rstandard(modelo)
plot(res_stud)
```
#### Normalidade

```{r}
envel_norm(modelo)
```

Os resíduos ainda não seguindo uma normal.

#### Homodedasticidade
```{r}
plot(y.hat,res_stud,xlab="Valores Ajustados", ylab="Resíduos estudentizados",pch=19)
```
Os resíduos não parecem ter variância constante.

#### Resíduo x variável explicativa
```{r}
plot(x2, res_stud, pch=19)
plot(x3, res_stud, pch=19)
```
Vamos incluir a variável $x_3^3$.

**Modelo  y ~ 1+ x2 + x2^2 + x3 + x3^2 não está validado, os presuposto não foram atendidos!!!**

### Mudanças

```{r}
modelo<-lm(y~1+x2+x3+I(x2^2)+I(x3^2)+I(x3^3))
summary(modelo)
```

### Análise de resíduos

```{r}
y.hat<-modelo$fitted.values
res_stud<-rstudent(modelo)
res_pad<-rstandard(modelo)
plot(res_stud)
```
#### Normalidade

```{r}
envel_norm(modelo)
```

Os resíduos ainda não estão ótimos, mas estão razoáveis.

#### Homodedasticidade
```{r}
plot(y.hat,res_stud,xlab="Valores Ajustados", ylab="Resíduos estudentizados",pch=19)
```
Os resíduos não parecem ter variância constante.

#### Resíduo x variável explicativa
```{r}
plot(x2, res_stud, pch=19)
plot(x3, res_stud, pch=19)
```
Não consegui chegar em um modelo validado adicionando mais termos das variáveis explicativas. Talvez seja necessário aplicar outra metodologia.